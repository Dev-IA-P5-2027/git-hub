{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c541c207",
   "metadata": {},
   "source": [
    "# Vocabulaire"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a2b6d",
   "metadata": {},
   "source": [
    "üîπ Apprentissage non supervis√©\n",
    "\n",
    "M√©thode d‚Äôapprentissage automatique o√π l‚Äôalgorithme d√©couvre seul des structures ou des regroupements dans les donn√©es, sans √©tiquettes pr√©alables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "610a54f3",
   "metadata": {},
   "source": [
    "üîπ Clustering\n",
    "\n",
    "Technique d‚Äôapprentissage non supervis√© qui consiste √† regrouper des donn√©es en clusters selon une mesure de similarit√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93a6461",
   "metadata": {},
   "source": [
    "üîπ K-means\n",
    "\n",
    "Algorithme qui partitionne les donn√©es en k clusters en minimisant la somme des distances au carr√© entre les points et le centre (moyenne) de leur cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de5bcb55",
   "metadata": {},
   "source": [
    "üîπ K-m√©do√Ødes\n",
    "\n",
    "Variante de k-means o√π le centre d‚Äôun cluster est un point r√©el du dataset (m√©do√Øde) plut√¥t que la moyenne. Plus robuste aux valeurs aberrantes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fdb551",
   "metadata": {},
   "source": [
    "üîπ DBSCAN\n",
    "\n",
    "Algorithme bas√© sur la densit√© qui regroupe les points fortement connect√©s entre eux et identifie les points isol√©s comme bruit, sans fixer le nombre de clusters √† l‚Äôavance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7914867",
   "metadata": {},
   "source": [
    "üîπ Inertie\n",
    "\n",
    "Somme des distances au carr√© entre chaque point et le centre de son cluster.\n",
    "Elle mesure la compacit√© des clusters. Plus elle est faible, plus les groupes sont serr√©s.\n",
    "\n",
    "En gros permet de voir la taille de la sph√®re du cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6143ca27",
   "metadata": {},
   "source": [
    "üîπ Standardisation\n",
    "\n",
    "Transformation des donn√©es pour qu‚Äôelles aient une moyenne nulle et un √©cart-type √©gal √† 1, afin que toutes les variables aient la m√™me importance dans le calcul des distances."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75c0e663",
   "metadata": {},
   "source": [
    "üîπ Elbow Method (m√©thode du coude)\n",
    "\n",
    "M√©thode permettant de choisir le nombre optimal de clusters en observant la diminution de l‚Äôinertie lorsque k augmente.\n",
    "On choisit le point o√π la r√©duction devient marginale, c‚Äôest-√†-dire au niveau du ‚Äúcoude‚Äù."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87671e1",
   "metadata": {},
   "source": [
    "üîπ Silhouette coefficient\n",
    "\n",
    "Mesure la qualit√© d‚Äôun clustering en comparant la distance moyenne d‚Äôun point √† son propre cluster et aux autres clusters.\n",
    "Il varie entre -1 et 1. Une valeur proche de 1 indique un bon regroupement.\n",
    "\n",
    "Silhouette -> le coef permet d'√©valuer pour chaque pts la distance entre le centre de leur cluster et celui des autre cluester."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8adbc557",
   "metadata": {},
   "source": [
    "üîπ Similarit√©\n",
    "\n",
    "Mesure indiquant √† quel point deux objets se ressemblent selon un crit√®re d√©fini (distance, corr√©lation, intersection, etc.)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac96fdae",
   "metadata": {},
   "source": [
    "üîπ Distance euclidienne\n",
    "\n",
    "Distance ‚Äú√† vol d‚Äôoiseau‚Äù entre deux points dans un espace.\n",
    "Formule classique issue du th√©or√®me de Pythagore."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d550b7f8",
   "metadata": {},
   "source": [
    "üîπ Distance Manhattan\n",
    "\n",
    "Distance mesur√©e comme la somme des diff√©rences absolues entre les coordonn√©es.\n",
    "On se d√©place en lignes droites horizontales et verticales, comme dans une ville en grille."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc25aa2b",
   "metadata": {},
   "source": [
    "üîπ Distance Jaccard\n",
    "\n",
    "Mesure de dissimilarit√© bas√©e sur la comparaison d‚Äôensembles :\n",
    "1 - (intersection / union).\n",
    "Utilis√©e souvent pour des donn√©es binaires ou textuelles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e4056d",
   "metadata": {},
   "source": [
    "üîπ Ground truth\n",
    "\n",
    "√âtiquettes r√©elles valid√©es par des humains servant de r√©f√©rence pour √©valuer les performances d‚Äôun mod√®le."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92f5ba56",
   "metadata": {},
   "source": [
    "üîπ Adjusted Rand Index (ARI)\n",
    "\n",
    "Mesure la similarit√© entre deux partitions en corrigeant l‚Äôeffet du hasard.\n",
    "Sa valeur varie entre -1 et 1, 1 indiquant une correspondance parfaite.\n",
    "\n",
    "On prend notre cluster et on prend uncluster de r√©f√©rence issue du ground thruth et on mesure la similarit√© entre les 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f1a9180",
   "metadata": {},
   "source": [
    "üîπ AMI (Adjusted Mutual Information)\n",
    "\n",
    "Mesure la quantit√© d‚Äôinformation partag√©e entre deux partitions, corrig√©e pour le hasard.\n",
    "\n",
    "Pareille, on prend le cluster et mle gro√†ud truth et on regarde si les donn√© en nombre de donn√© se recoupe correctement ou pas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7e1dd7",
   "metadata": {},
   "source": [
    "üîπ Maximal Distance to Cluster Center\n",
    "\n",
    "Distance maximale entre un point d‚Äôun cluster et son centre.\n",
    "Indique la dispersion maximale dans le cluster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8ba037d",
   "metadata": {},
   "source": [
    "üîπ Average Distance to Other Cluster\n",
    "\n",
    "Distance moyenne entre les points d‚Äôun cluster et ceux des autres clusters.\n",
    "Mesure la s√©paration entre groupes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb8fe1b",
   "metadata": {},
   "source": [
    "David truc Index : Permet de masurer la diff√©rence de similarit√© entre deux cluster de l'acquisition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0dc0b",
   "metadata": {},
   "source": [
    "Calenski : permet d'√©valuer le ratio de la diff√©rence de distance entre les cluster et le regroupement relatif des pts du cluster.\n",
    "\n",
    "Engros plus les cluster sont bien s√©par√© les un des autre et ont leur pts de cluster regoup√©. Plus l'algorythme de clustering est colrrect."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba9b6ad9",
   "metadata": {},
   "source": [
    "# Hypoth√®se"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fd8a753",
   "metadata": {},
   "source": [
    "On peut entra√Æner un mod√®le de classification en utilisant les labels produits par un algorithme de clustering, puis v√©rifier si ces clusters sont suffisamment coh√©rents pour √™tre pr√©dits correctement par un classifieur.\n",
    "\n",
    "En clair :\n",
    "Si un classifieur arrive facilement √† apprendre √† pr√©dire les clusters trouv√©s, alors ces clusters ont probablement une structure claire et exploitable.\n",
    "\n",
    "Pourquoi √ßa marche ?\n",
    "\n",
    "Le clustering est non supervis√©.\n",
    "La classification est supervis√©e.\n",
    "\n",
    "Donc on fait :\n",
    "\n",
    "Clustering ‚Üí obtention de pseudo-labels\n",
    "\n",
    "Classification ‚Üí apprentissage d‚Äôun mod√®le pour pr√©dire ces pseudo-labels\n",
    "\n",
    "√âvaluation ‚Üí si la pr√©cision est √©lev√©e, les clusters sont bien s√©parables\n",
    "\n",
    "Si la classification est mauvaise, √ßa veut dire que :\n",
    "\n",
    "Les clusters se chevauchent\n",
    "\n",
    "Ils sont instables\n",
    "\n",
    "Ils sont peu coh√©rents\n",
    "\n",
    "Exemple concret\n",
    "\n",
    "On applique K-means sur des donn√©es.\n",
    "On obtient 3 clusters.\n",
    "\n",
    "Ensuite :\n",
    "\n",
    "On entra√Æne un classifieur (par exemple une r√©gression logistique ou un SVM)\n",
    "\n",
    "On mesure l‚Äôaccuracy via validation crois√©e\n",
    "\n",
    "Si l‚Äôaccuracy est √©lev√©e ‚Üí les clusters sont bien structur√©s.\n",
    "Si elle est faible ‚Üí clustering douteux.\n",
    "\n",
    "Attention quand m√™me\n",
    "\n",
    "Ce n‚Äôest pas une ‚Äúpreuve‚Äù absolue de qualit√© :\n",
    "\n",
    "Un classifieur puissant peut apprendre des fronti√®res complexes m√™me si les clusters sont artificiels.\n",
    "\n",
    "Si les clusters sont mal choisis (mauvais k), la classification peut quand m√™me fonctionner.\n",
    "\n",
    "Donc ce n‚Äôest pas une v√©rit√© universelle. C‚Äôest un indicateur suppl√©mentaire.\n",
    "\n",
    "En r√©sum√© :\n",
    "\n",
    "Utiliser la classification pour v√©rifier un clustering revient √† tester si les groupes d√©couverts sont suffisamment distincts pour √™tre pr√©dits par un mod√®le supervis√©.\n",
    "\n",
    "C‚Äôest une mani√®re √©l√©gante de transformer un probl√®me non supervis√© en probl√®me supervis√© pour en √©valuer la coh√©rence.\n",
    "\n",
    "Jesse n‚Äôa pas tort. Ce qui est rare."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be7c26a2",
   "metadata": {},
   "source": [
    "On peut utiliser la classification pour √©valuer un clustering en entra√Ænant un classifieur sur les labels g√©n√©r√©s par le clustering.\n",
    "Si le classifieur obtient une bonne performance, cela signifie que les clusters sont bien s√©par√©s et coh√©rents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e692dee",
   "metadata": {},
   "source": [
    "# Probl√©matique "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be7da88",
   "metadata": {},
   "source": [
    "Probl√©matique 1 : \n",
    "\n",
    "1Ô∏è‚É£ Comment construire des mod√®les de clustering ?\n",
    "\n",
    "Construire un mod√®le de clustering consiste √† :\n",
    "\n",
    "Pr√©parer les donn√©es\n",
    "\n",
    "Nettoyage\n",
    "\n",
    "Gestion des valeurs manquantes\n",
    "\n",
    "Standardisation\n",
    "\n",
    "Choisir un algorithme adapt√©\n",
    "\n",
    "K-means si clusters compacts et sph√©riques\n",
    "\n",
    "DBSCAN si formes complexes et pr√©sence de bruit\n",
    "\n",
    "Hi√©rarchique si on veut une structure arborescente\n",
    "\n",
    "Choisir les param√®tres\n",
    "\n",
    "Nombre de clusters (k)\n",
    "\n",
    "Distance\n",
    "\n",
    "Param√®tres de densit√© (eps, min_samples)\n",
    "\n",
    "Entra√Æner le mod√®le et analyser les r√©sultats\n",
    "\n",
    "En r√©sum√© :\n",
    "pr√©paration ‚Üí choix de l‚Äôalgorithme ‚Üí r√©glage des param√®tres ‚Üí validation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305737b0",
   "metadata": {},
   "source": [
    "Probl√©matique 2 :\n",
    "\n",
    "2Ô∏è‚É£ Comment √©valuer et choisir les m√©triques pertinentes ?\n",
    "\n",
    "Le choix d√©pend du contexte :\n",
    "\n",
    "Si on a un ground truth ‚Üí utiliser ARI, AMI, Rand Index.\n",
    "\n",
    "Si on n‚Äôa pas de labels ‚Üí utiliser Silhouette, Davies-Bouldin, Calinski-Harabasz.\n",
    "\n",
    "On choisit la m√©trique selon :\n",
    "\n",
    "La pr√©sence ou non de v√©rit√© terrain\n",
    "\n",
    "Le type de donn√©es\n",
    "\n",
    "L‚Äôobjectif (compacit√©, s√©paration, stabilit√©)\n",
    "\n",
    "En r√©sum√© :\n",
    "la m√©trique doit correspondre au type de validation possible et √† l‚Äôobjectif du clustering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7713544f",
   "metadata": {},
   "source": [
    "Probl√©matique 3 :\n",
    "\n",
    "3Ô∏è‚É£ Comment d√©terminer le nombre de clusters optimal ?\n",
    "\n",
    "M√©thodes courantes :\n",
    "\n",
    "M√©thode du coude (Elbow method)\n",
    "\n",
    "Silhouette score (maximiser la valeur moyenne)\n",
    "\n",
    "Gap statistic\n",
    "\n",
    "Analyse m√©tier (interpr√©tabilit√©)\n",
    "\n",
    "Le bon nombre de clusters est souvent un compromis entre performance math√©matique et interpr√©tation pratique.\n",
    "\n",
    "En r√©sum√© :\n",
    "on teste plusieurs valeurs de k et on choisit celle qui √©quilibre qualit√© et simplicit√©."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49de99f7",
   "metadata": {},
   "source": [
    "Probl√©matique 4 :\n",
    "\n",
    "4Ô∏è‚É£ Comment r√©duire la dimensionnalit√© avec K-means ?\n",
    "\n",
    "K-means peut √™tre utilis√© pour la r√©duction dimensionnelle via :\n",
    "\n",
    "Vector quantization\n",
    "Chaque point est remplac√© par le centre de son cluster.\n",
    "\n",
    "Repr√©sentation par distances aux centro√Ødes\n",
    "Les distances aux k centres deviennent les nouvelles features.\n",
    "\n",
    "Cela permet de compresser l‚Äôinformation tout en conservant la structure globale.\n",
    "\n",
    "En r√©sum√© :\n",
    "K-means r√©duit la dimension en repr√©sentant les donn√©es par leurs centres de clusters plut√¥t que par leurs coordonn√©es initiales."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RER_7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "-1.-1.-1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
